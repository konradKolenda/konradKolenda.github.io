<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Complete Guide to dbt Incremental Strategies</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            overflow: hidden;
        }
        
        .header {
            background: linear-gradient(135deg, #2c3e50 0%, #3498db 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }
        
        .header h1 {
            margin: 0;
            font-size: 2.8rem;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        
        .header p {
            margin: 15px 0 0 0;
            font-size: 1.3rem;
            opacity: 0.9;
        }
        
        .content {
            padding: 40px;
        }
        
        .toc {
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            border-radius: 10px;
            padding: 25px;
            margin: 20px 0;
            border-left: 5px solid #3498db;
        }
        
        .toc h3 {
            margin-top: 0;
            color: #2c3e50;
            font-size: 1.4rem;
        }
        
        .toc-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 15px;
            margin-top: 20px;
        }
        
        .toc-item {
            background: white;
            padding: 15px;
            border-radius: 8px;
            border-left: 3px solid #3498db;
        }
        
        .toc a {
            color: #3498db;
            text-decoration: none;
            font-weight: 600;
        }
        
        .toc a:hover {
            text-decoration: underline;
        }
        
        .section {
            margin-bottom: 60px;
            border-left: 4px solid #3498db;
            padding-left: 25px;
        }
        
        .section h2 {
            color: #2c3e50;
            font-size: 2rem;
            margin-bottom: 25px;
            border-bottom: 3px solid #ecf0f1;
            padding-bottom: 15px;
        }
        
        .section h3 {
            color: #34495e;
            font-size: 1.5rem;
            margin-top: 35px;
            margin-bottom: 20px;
        }
        
        .strategy-overview {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 25px;
            margin: 30px 0;
        }
        
        .strategy-card {
            background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
            border: 2px solid #e9ecef;
            border-radius: 15px;
            padding: 25px;
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
        }
        
        .strategy-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 4px;
            background: linear-gradient(135deg, #3498db 0%, #2980b9 100%);
        }
        
        .strategy-card:hover {
            transform: translateY(-8px);
            box-shadow: 0 15px 35px rgba(0,0,0,0.1);
            border-color: #3498db;
        }
        
        .strategy-card h4 {
            color: #2c3e50;
            margin-top: 0;
            font-size: 1.4rem;
            margin-bottom: 15px;
        }
        
        .strategy-badges {
            display: flex;
            gap: 8px;
            margin-bottom: 15px;
            flex-wrap: wrap;
        }
        
        .badge {
            padding: 4px 12px;
            border-radius: 20px;
            font-size: 0.85rem;
            font-weight: 600;
        }
        
        .badge-insert { background: #d4edda; color: #155724; }
        .badge-update { background: #fff3cd; color: #856404; }
        .badge-delete { background: #f8d7da; color: #721c24; }
        .badge-performance { background: #cce5ff; color: #004085; }
        
        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 30px 0;
            background: white;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 8px 25px rgba(0,0,0,0.1);
        }
        
        .comparison-table th {
            background: linear-gradient(135deg, #3498db 0%, #2980b9 100%);
            color: white;
            padding: 18px 15px;
            text-align: left;
            font-weight: 600;
            font-size: 1rem;
        }
        
        .comparison-table td {
            padding: 15px;
            border-bottom: 1px solid #ecf0f1;
            vertical-align: top;
        }
        
        .comparison-table tr:nth-child(even) {
            background: #f8f9fa;
        }
        
        .comparison-table tr:hover {
            background: #e3f2fd;
        }
        
        .code-block {
            background: #2c3e50;
            color: #ecf0f1;
            padding: 25px;
            border-radius: 10px;
            margin: 25px 0;
            overflow-x: auto;
            font-family: 'Monaco', 'Consolas', monospace;
            font-size: 0.9rem;
            line-height: 1.5;
            border-left: 5px solid #4299e1;
            position: relative;
        }
        
        .code-block::before {
            content: 'SQL';
            position: absolute;
            top: 8px;
            right: 15px;
            background: #4299e1;
            color: white;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 0.7rem;
            font-weight: bold;
        }
        
        .pros-cons {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 25px 0;
        }
        
        .pros, .cons {
            padding: 20px;
            border-radius: 10px;
        }
        
        .pros {
            background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%);
            border-left: 5px solid #28a745;
        }
        
        .cons {
            background: linear-gradient(135deg, #f8d7da 0%, #f1aeb5 100%);
            border-left: 5px solid #dc3545;
        }
        
        .pros h5, .cons h5 {
            margin-top: 0;
            font-size: 1.2rem;
            font-weight: 600;
        }
        
        .warning-box {
            background: linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%);
            border: 2px solid #ffc107;
            border-radius: 10px;
            padding: 20px;
            margin: 25px 0;
            border-left: 5px solid #f39c12;
        }
        
        .warning-box h4 {
            color: #856404;
            margin-top: 0;
            font-size: 1.3rem;
        }
        
        .decision-tree {
            background: linear-gradient(135deg, #e8f5e8 0%, #d4f1d4 100%);
            border: 2px solid #28a745;
            border-radius: 15px;
            padding: 30px;
            margin: 30px 0;
        }
        
        .decision-tree h4 {
            color: #155724;
            margin-top: 0;
            font-size: 1.4rem;
            text-align: center;
        }
        
        .decision-step {
            background: white;
            border-radius: 8px;
            padding: 15px;
            margin: 15px 0;
            border-left: 4px solid #28a745;
        }
        
        .highlight {
            background: linear-gradient(120deg, #a8edea 0%, #fed6e3 100%);
            padding: 2px 8px;
            border-radius: 5px;
            font-weight: 600;
        }
        
        .performance-indicator {
            display: inline-flex;
            align-items: center;
            gap: 5px;
        }
        
        .perf-bar {
            width: 60px;
            height: 8px;
            background: #ecf0f1;
            border-radius: 4px;
            overflow: hidden;
        }
        
        .perf-fill {
            height: 100%;
            border-radius: 4px;
        }
        
        .perf-high { background: #28a745; width: 90%; }
        .perf-medium { background: #ffc107; width: 60%; }
        .perf-low { background: #dc3545; width: 30%; }
        
        .warehouse-support {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        
        .warehouse-item {
            background: white;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 15px;
            text-align: center;
        }
        
        .warehouse-item.supported {
            border-color: #28a745;
            background: #f8fff9;
        }
        
        .warehouse-item.partial {
            border-color: #ffc107;
            background: #fffdf5;
        }
        
        .warehouse-item.not-supported {
            border-color: #dc3545;
            background: #fff5f5;
        }
        
        @media (max-width: 768px) {
            .pros-cons {
                grid-template-columns: 1fr;
            }
            
            .strategy-overview {
                grid-template-columns: 1fr;
            }
            
            .header h1 {
                font-size: 2.2rem;
            }
            
            .content {
                padding: 20px;
            }
            
            .toc-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>📈 Complete Guide to dbt Incremental Strategies</h1>
            <p>Master Every Approach to Incremental Data Loading</p>
        </div>
        
        <div class="content">
            <div class="toc">
                <h3>📋 Navigation</h3>
                <div class="toc-grid">
                    <div class="toc-item">
                        <a href="#overview">🎯 Strategy Overview</a>
                        <p>Quick comparison of all strategies</p>
                    </div>
                    <div class="toc-item">
                        <a href="#delete-insert">🔄 Delete + Insert</a>
                        <p>The default strategy</p>
                    </div>
                    <div class="toc-item">
                        <a href="#merge">🔀 Merge</a>
                        <p>Database-native MERGE</p>
                    </div>
                    <div class="toc-item">
                        <a href="#append">➕ Append</a>
                        <p>Insert-only strategy</p>
                    </div>
                    <div class="toc-item">
                        <a href="#insert-overwrite">🔁 Insert Overwrite</a>
                        <p>Partition-level replacement</p>
                    </div>
                    <div class="toc-item">
                        <a href="#microbatch">⚡ Microbatch</a>
                        <p>Time-based processing</p>
                    </div>
                    <div class="toc-item">
                        <a href="#decision-guide">🧭 Decision Guide</a>
                        <p>Which strategy to choose</p>
                    </div>
                </div>
            </div>

            <div id="overview" class="section">
                <h2>🎯 Strategy Overview</h2>
                
                <div class="strategy-overview">
                    <div class="strategy-card">
                        <h4>delete+insert (Default)</h4>
                        <div class="strategy-badges">
                            <span class="badge badge-insert">✅ Insert</span>
                            <span class="badge badge-update">✅ Update</span>
                            <span class="badge badge-delete">❌ Delete</span>
                            <span class="badge badge-performance">Medium Performance</span>
                        </div>
                        <p>Deletes existing records matching the unique_key, then inserts all new data. Most reliable and widely supported.</p>
                    </div>

                    <div class="strategy-card">
                        <h4>merge</h4>
                        <div class="strategy-badges">
                            <span class="badge badge-insert">✅ Insert</span>
                            <span class="badge badge-update">✅ Update</span>
                            <span class="badge badge-delete">⚠️ Configurable</span>
                            <span class="badge badge-performance">High Performance</span>
                        </div>
                        <p>Uses database-native MERGE statements. Best performance for large datasets with many updates.</p>
                    </div>

                    <div class="strategy-card">
                        <h4>append</h4>
                        <div class="strategy-badges">
                            <span class="badge badge-insert">✅ Insert</span>
                            <span class="badge badge-update">❌ No Update</span>
                            <span class="badge badge-delete">❌ Delete</span>
                            <span class="badge badge-performance">Highest Performance</span>
                        </div>
                        <p>Simply appends new rows. Perfect for event logs and time-series data. Creates duplicates if used incorrectly.</p>
                    </div>

                    <div class="strategy-card">
                        <h4>insert_overwrite</h4>
                        <div class="strategy-badges">
                            <span class="badge badge-insert">✅ Insert</span>
                            <span class="badge badge-update">✅ Update (Partition)</span>
                            <span class="badge badge-delete">✅ Delete (Partition)</span>
                            <span class="badge badge-performance">High Performance</span>
                        </div>
                        <p>Overwrites entire partitions. Excellent for time-partitioned data with complete daily/hourly loads.</p>
                    </div>

                    <div class="strategy-card">
                        <h4>microbatch</h4>
                        <div class="strategy-badges">
                            <span class="badge badge-insert">✅ Insert</span>
                            <span class="badge badge-update">✅ Update</span>
                            <span class="badge badge-delete">❌ Delete</span>
                            <span class="badge badge-performance">Optimized Performance</span>
                        </div>
                        <p>Processes data in time-based batches. Ideal for large datasets with consistent time-based partitioning.</p>
                    </div>
                </div>

                <h3>Complete Comparison Table</h3>
                <table class="comparison-table">
                    <thead>
                        <tr>
                            <th>Strategy</th>
                            <th>Inserts</th>
                            <th>Updates</th>
                            <th>Deletes</th>
                            <th>Performance</th>
                            <th>Best For</th>
                            <th>Warehouse Support</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>delete+insert</strong></td>
                            <td>✅ Yes</td>
                            <td>✅ Yes</td>
                            <td>❌ No</td>
                            <td><span class="performance-indicator">Medium <div class="perf-bar"><div class="perf-fill perf-medium"></div></div></span></td>
                            <td>General purpose, reliable</td>
                            <td>All warehouses</td>
                        </tr>
                        <tr>
                            <td><strong>merge</strong></td>
                            <td>✅ Yes</td>
                            <td>✅ Yes</td>
                            <td>⚠️ Optional</td>
                            <td><span class="performance-indicator">High <div class="perf-bar"><div class="perf-fill perf-high"></div></div></span></td>
                            <td>Large datasets, many updates</td>
                            <td>BigQuery, Snowflake, Databricks</td>
                        </tr>
                        <tr>
                            <td><strong>append</strong></td>
                            <td>✅ Yes</td>
                            <td>❌ No</td>
                            <td>❌ No</td>
                            <td><span class="performance-indicator">Highest <div class="perf-bar"><div class="perf-fill perf-high"></div></div></span></td>
                            <td>Event logs, time-series</td>
                            <td>All warehouses</td>
                        </tr>
                        <tr>
                            <td><strong>insert_overwrite</strong></td>
                            <td>✅ Yes</td>
                            <td>✅ Partition-level</td>
                            <td>✅ Partition-level</td>
                            <td><span class="performance-indicator">High <div class="perf-bar"><div class="perf-fill perf-high"></div></div></span></td>
                            <td>Time-partitioned data</td>
                            <td>BigQuery, Spark/Databricks</td>
                        </tr>
                        <tr>
                            <td><strong>microbatch</strong></td>
                            <td>✅ Yes</td>
                            <td>✅ Yes</td>
                            <td>❌ No</td>
                            <td><span class="performance-indicator">Optimized <div class="perf-bar"><div class="perf-fill perf-high"></div></div></span></td>
                            <td>Large time-series datasets</td>
                            <td>All warehouses (dbt 1.9+)</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <div id="delete-insert" class="section">
                <h2>🔄 Delete + Insert Strategy (Default)</h2>
                
                <p>The <span class="highlight">delete+insert</span> strategy is dbt's default incremental approach. It's the most reliable and universally supported method.</p>

                <h3>How It Works</h3>
                <p><strong>📋 Code Examples:</strong> 
                <a href="https://github.com/konradKolenda/konradKolenda.github.io/blob/main/dbt/code_examples/dbt_incremental_strategies_guide/01_delete_insert_basic.sql" target="_blank">Basic Implementation</a> | 
                <a href="https://github.com/konradKolenda/konradKolenda.github.io/blob/main/dbt/code_examples/dbt_incremental_strategies_guide/02_delete_insert_advanced.sql" target="_blank">Advanced Configuration</a>
                </p>
                <div class="code-block">{{
  config(
    materialized='incremental',
    unique_key='customer_id'  -- Required for updates
    -- incremental_strategy='delete+insert' -- This is the default
  )
}}

with incremental_data as (
  select
    customer_id,
    customer_name,
    email,
    phone,
    last_updated
  from {{ ref('stg_customers') }}
  
  {% if is_incremental() %}
    -- Only process changed records
    where last_updated > (select max(last_updated) from {{ this }})
  {% endif %}
)

select * from incremental_data

-- BEHIND THE SCENES:
-- Step 1: DELETE FROM target WHERE customer_id IN (1, 2, 3, ...)
-- Step 2: INSERT INTO target SELECT * FROM incremental_data</div>

                <div class="pros-cons">
                    <div class="pros">
                        <h5>✅ Advantages</h5>
                        <ul>
                            <li><strong>Universal support</strong>: Works on all data warehouses</li>
                            <li><strong>Reliable</strong>: Simple logic, easy to debug</li>
                            <li><strong>Handles updates</strong>: Automatically updates existing records</li>
                            <li><strong>Transactional safety</strong>: Atomic operation in most warehouses</li>
                            <li><strong>No special features required</strong>: Uses basic SQL</li>
                        </ul>
                    </div>
                    <div class="cons">
                        <h5>❌ Limitations</h5>
                        <ul>
                            <li><strong>Two operations</strong>: DELETE + INSERT (can be slower)</li>
                            <li><strong>No deletion handling</strong>: Doesn't remove records deleted in source</li>
                            <li><strong>Lock contention</strong>: May cause brief table locks</li>
                            <li><strong>Inefficient for sparse updates</strong>: Rewrites entire rows</li>
                        </ul>
                    </div>
                </div>

                <h3>Advanced Configuration</h3>
                <div class="code-block">{{
  config(
    materialized='incremental',
    unique_key='customer_id',
    incremental_strategy='delete+insert',
    
    -- Control which columns to exclude from updates
    merge_exclude_columns=['created_at', 'inserted_by'],
    
    -- Add conditions to the DELETE statement
    incremental_predicates=[
      "DBT_INTERNAL_DEST.last_updated < current_timestamp - interval '30 days'"
    ]
  )
}}

-- Example: Only update records that have actually changed
select
  customer_id,
  customer_name,
  email,
  phone,
  last_updated,
  
  -- Create a hash to detect actual changes
  {{ dbt_utils.generate_surrogate_key([
    'customer_name', 'email', 'phone'
  ]) }} as row_hash
  
from {{ ref('stg_customers') }}

{% if is_incremental() %}
  where last_updated > (select max(last_updated) from {{ this }})
  -- Only include records where content actually changed
  and {{ dbt_utils.generate_surrogate_key([
    'customer_name', 'email', 'phone'
  ]) }} not in (
    select row_hash from {{ this }}
    where customer_id in (
      select customer_id from {{ ref('stg_customers') }}
      where last_updated > (select max(last_updated) from {{ this }})
    )
  )
{% endif %}</div>

                <div class="warning-box">
                    <h4>⚠️ Important Considerations</h4>
                    <ul>
                        <li><strong>unique_key is mandatory</strong> for updates to work properly</li>
                        <li><strong>NULL values in unique_key</strong> will cause issues - always validate</li>
                        <li><strong>Composite keys</strong> should be provided as a list: <code>unique_key=['col1', 'col2']</code></li>
                        <li><strong>Performance impact</strong>: DELETE operations scan the entire table</li>
                    </ul>
                </div>
            </div>

            <div id="merge" class="section">
                <h2>🔀 Merge Strategy</h2>
                
                <p>The <span class="highlight">merge</span> strategy uses database-native MERGE statements for optimal performance, especially with large datasets containing many updates.</p>

                <h3>Basic Implementation</h3>
                <p><strong>📋 Code Examples:</strong> 
                <a href="https://github.com/konradKolenda/konradKolenda.github.io/blob/main/dbt/code_examples/dbt_incremental_strategies_guide/03_merge_basic.sql" target="_blank">Basic Merge</a> | 
                <a href="https://github.com/konradKolenda/konradKolenda.github.io/blob/main/dbt/code_examples/dbt_incremental_strategies_guide/04_merge_with_deletes.sql" target="_blank">Advanced with Deletes</a>
                </p>
                <div class="code-block">{{
  config(
    materialized='incremental',
    unique_key='customer_id',
    incremental_strategy='merge'
  )
}}

select
  customer_id,
  customer_name,
  email,
  phone,
  subscription_status,
  last_updated
from {{ ref('stg_customers') }}

{% if is_incremental() %}
  where last_updated > (select max(last_updated) from {{ this }})
{% endif %}

-- GENERATES NATIVE MERGE STATEMENT:
-- MERGE target USING source ON target.customer_id = source.customer_id
-- WHEN MATCHED THEN UPDATE SET ...
-- WHEN NOT MATCHED THEN INSERT ...</div>

                <h3>Advanced Merge with Deletion Support</h3>
                <div class="code-block">{{
  config(
    materialized='incremental',
    unique_key='customer_id',
    incremental_strategy='merge',
    
    -- Exclude certain columns from being updated
    merge_exclude_columns=['created_at', 'first_seen'],
    
    -- Add deletion logic
    merge_update_columns={
      'customer_name': 'source.customer_name',
      'email': 'source.email',
      'is_active': 'source.is_active'
    }
  )
}}

with source_with_deletes as (
  select
    customer_id,
    customer_name,
    email,
    phone,
    is_active,
    last_updated,
    
    -- Mark records for deletion
    case 
      when is_active = false then true 
      else false 
    end as _should_delete
    
  from {{ ref('stg_customers') }}
  
  {% if is_incremental() %}
    where last_updated > (select max(last_updated) from {{ this }})
       or is_active = false  -- Always include records marked for deletion
  {% endif %}
)

select * from source_with_deletes

-- ADVANCED: Custom merge with deletion (warehouse-specific)
-- BigQuery example:
-- MERGE target T USING source S ON T.customer_id = S.customer_id
-- WHEN MATCHED AND S._should_delete = true THEN DELETE
-- WHEN MATCHED AND S._should_delete = false THEN UPDATE SET ...
-- WHEN NOT MATCHED AND S._should_delete = false THEN INSERT ...</div>

                <h3>Warehouse-Specific Features</h3>
                
                <div class="warehouse-support">
                    <div class="warehouse-item supported">
                        <h5>BigQuery</h5>
                        <p>✅ Full MERGE support<br>✅ DELETE in MERGE<br>✅ Complex conditions</p>
                    </div>
                    <div class="warehouse-item supported">
                        <h5>Snowflake</h5>
                        <p>✅ Full MERGE support<br>✅ DELETE in MERGE<br>✅ Multi-table operations</p>
                    </div>
                    <div class="warehouse-item supported">
                        <h5>Databricks</h5>
                        <p>✅ Delta Lake MERGE<br>✅ Time travel<br>✅ Optimized performance</p>
                    </div>
                    <div class="warehouse-item partial">
                        <h5>Redshift</h5>
                        <p>⚠️ Limited MERGE<br>❌ No DELETE in MERGE<br>✅ Basic operations</p>
                    </div>
                    <div class="warehouse-item not-supported">
                        <h5>PostgreSQL</h5>
                        <p>❌ No native MERGE<br>⚠️ Falls back to delete+insert<br>✅ Works but slower</p>
                    </div>
                </div>

                <div class="pros-cons">
                    <div class="pros">
                        <h5>✅ Advantages</h5>
                        <ul>
                            <li><strong>Best performance</strong>: Single operation vs DELETE+INSERT</li>
                            <li><strong>Atomic operation</strong>: True ACID compliance</li>
                            <li><strong>Efficient updates</strong>: Only changes modified columns</li>
                            <li><strong>Deletion support</strong>: Can handle DELETEs in same operation</li>
                            <li><strong>Less locking</strong>: Reduced contention on target table</li>
                        </ul>
                    </div>
                    <div class="cons">
                        <h5>❌ Limitations</h5>
                        <ul>
                            <li><strong>Warehouse dependent</strong>: Not supported everywhere</li>
                            <li><strong>Complex syntax</strong>: Harder to debug when issues arise</li>
                            <li><strong>Feature variations</strong>: Different capabilities per warehouse</li>
                            <li><strong>Memory usage</strong>: Can require more memory for large merges</li>
                        </ul>
                    </div>
                </div>
            </div>

            <div id="append" class="section">
                <h2>➕ Append Strategy</h2>
                
                <p>The <span class="highlight">append</span> strategy simply adds new rows to the target table without any deduplication or updating. Perfect for event logs and time-series data.</p>

                <h3>Basic Implementation</h3>
                <p><strong>📋 Code Examples:</strong> 
                <a href="https://github.com/konradKolenda/konradKolenda.github.io/blob/main/dbt/code_examples/dbt_incremental_strategies_guide/05_append_basic.sql" target="_blank">Basic Append</a> | 
                <a href="https://github.com/konradKolenda/konradKolenda.github.io/blob/main/dbt/code_examples/dbt_incremental_strategies_guide/06_append_event_logging.sql" target="_blank">Event Logging</a> | 
                <a href="https://github.com/konradKolenda/konradKolenda.github.io/blob/main/dbt/code_examples/dbt_incremental_strategies_guide/07_append_safe_patterns.sql" target="_blank">Safe Patterns</a>
                </p>
                <div class="code-block">{{
  config(
    materialized='incremental',
    incremental_strategy='append'
    -- unique_key is IGNORED with append strategy
  )
}}

with new_events as (
  select
    event_id,
    user_id,
    event_type,
    event_timestamp,
    properties
  from {{ ref('stg_events') }}
  
  {% if is_incremental() %}
    -- Only get events since last run
    where event_timestamp > (select max(event_timestamp) from {{ this }})
  {% endif %}
)

select * from new_events

-- BEHIND THE SCENES:
-- Simply: INSERT INTO target SELECT * FROM new_events
-- No DELETE operations, no deduplication</div>

                <h3>Perfect Use Cases</h3>
                <div class="code-block">-- Event Logging Table
{{
  config(
    materialized='incremental',
    incremental_strategy='append',
    partition_by={'field': 'event_date', 'data_type': 'date'}
  )
}}

select
  event_id,                    -- Naturally unique (UUID, timestamp-based)
  user_id,
  event_type,
  event_timestamp,
  date(event_timestamp) as event_date,
  session_id,
  page_url,
  referrer,
  user_agent,
  properties                   -- JSON/variant column
from {{ ref('stg_web_events') }}

{% if is_incremental() %}
  where event_timestamp > (select max(event_timestamp) from {{ this }})
{% endif %}

-- Time Series Data (IoT Sensors)
{{
  config(
    materialized='incremental',
    incremental_strategy='append',
    cluster_by=['sensor_id', 'measurement_timestamp']
  )
}}

select
  sensor_id,
  measurement_timestamp,
  temperature,
  humidity,
  pressure,
  battery_level
from {{ ref('stg_sensor_readings') }}

{% if is_incremental() %}
  where measurement_timestamp > (select max(measurement_timestamp) from {{ this }})
{% endif %}</div>

                <div class="warning-box">
                    <h4>⚠️ Critical Warning: Duplicate Risk</h4>
                    <p>The append strategy will create <strong>duplicates</strong> if you have:</p>
                    <ul>
                        <li>Records with the same business key but different timestamps</li>
                        <li>Late-arriving data that overlaps with previous runs</li>
                        <li>Source system that updates existing records</li>
                        <li>Backfill scenarios where you reprocess historical data</li>
                    </ul>
                    
                    <div class="code-block">-- ❌ BAD: This will create duplicates
{{
  config(
    materialized='incremental',
    incremental_strategy='append'  -- Wrong choice!
  )
}}

select
  customer_id,     -- Same customer can appear multiple times
  customer_name,   -- Customer name might get updated
  email,
  last_updated
from customers

-- Result: Multiple rows per customer = data corruption!</div>
                </div>

                <h3>Safe Append Patterns</h3>
                <div class="code-block">-- Pattern 1: Natural Uniqueness with Immutable Events
{{
  config(
    materialized='incremental',
    incremental_strategy='append'
  )
}}

select
  {{ dbt_utils.generate_surrogate_key([
    'user_id', 'event_timestamp', 'event_type'
  ]) }} as event_id,           -- Generate unique ID
  user_id,
  event_type,
  event_timestamp,
  properties
from {{ ref('stg_events') }}

{% if is_incremental() %}
  where event_timestamp > (select max(event_timestamp) from {{ this }})
  -- Add safety check to prevent duplicates
  and {{ dbt_utils.generate_surrogate_key([
    'user_id', 'event_timestamp', 'event_type'
  ]) }} not in (select event_id from {{ this }})
{% endif %}

-- Pattern 2: Deduplication Before Append
{{
  config(
    materialized='incremental',
    incremental_strategy='append',
    pre_hook="delete from {{ this }} where created_date = current_date"  -- Clean today's data first
  )
}}

with deduplicated_data as (
  select
    transaction_id,
    customer_id,
    amount,
    transaction_timestamp,
    date(transaction_timestamp) as created_date,
    
    -- Remove duplicates within the batch
    row_number() over (
      partition by transaction_id 
      order by transaction_timestamp desc
    ) as rn
    
  from {{ ref('stg_transactions') }}
  
  {% if is_incremental() %}
    where date(transaction_timestamp) >= current_date - interval '1' day
  {% endif %}
)

select * from deduplicated_data where rn = 1</div>

                <div class="pros-cons">
                    <div class="pros">
                        <h5>✅ Advantages</h5>
                        <ul>
                            <li><strong>Fastest performance</strong>: Single INSERT operation</li>
                            <li><strong>Simple logic</strong>: Easy to understand and debug</li>
                            <li><strong>No locks</strong>: Minimal contention on target table</li>
                            <li><strong>Perfect for events</strong>: Natural fit for immutable data</li>
                            <li><strong>Universal support</strong>: Works on all databases</li>
                        </ul>
                    </div>
                    <div class="cons">
                        <h5>❌ Limitations</h5>
                        <ul>
                            <li><strong>No updates</strong>: Cannot modify existing records</li>
                            <li><strong>Duplicate risk</strong>: Easy to accidentally create duplicates</li>
                            <li><strong>No deletion</strong>: Cannot remove records</li>
                            <li><strong>Limited use cases</strong>: Only suitable for append-only data</li>
                        </ul>
                    </div>
                </div>
            </div>

            <div id="insert-overwrite" class="section">
                <h2>🔁 Insert Overwrite Strategy</h2>
                
                <p>The <span class="highlight">insert_overwrite</span> strategy completely replaces entire partitions with new data. Perfect for time-partitioned data where you get complete datasets.</p>

                <h3>Basic Implementation</h3>
                <p><strong>📋 Code Examples:</strong> 
                <a href="https://github.com/konradKolenda/konradKolenda.github.io/blob/main/dbt/code_examples/dbt_incremental_strategies_guide/08_insert_overwrite_basic.sql" target="_blank">Basic Implementation</a> | 
                <a href="https://github.com/konradKolenda/konradKolenda.github.io/blob/main/dbt/code_examples/dbt_incremental_strategies_guide/09_insert_overwrite_dynamic.sql" target="_blank">Dynamic Partitions</a> | 
                <a href="https://github.com/konradKolenda/konradKolenda.github.io/blob/main/dbt/code_examples/dbt_incremental_strategies_guide/10_insert_overwrite_hourly.sql" target="_blank">Hourly Partitioning</a>
                </p>
                <div class="code-block">{{
  config(
    materialized='incremental',
    incremental_strategy='insert_overwrite',
    partition_by={'field': 'order_date', 'data_type': 'date'}
  )
}}

with daily_orders as (
  select
    order_id,
    customer_id,
    order_amount,
    order_status,
    order_timestamp,
    date(order_timestamp) as order_date
  from {{ ref('stg_orders') }}
  
  {% if is_incremental() %}
    -- Only process recent dates (will overwrite entire partitions)
    where date(order_timestamp) >= current_date - interval '7' day
  {% endif %}
)

select * from daily_orders

-- BEHIND THE SCENES:
-- 1. Identifies which partitions contain new data
-- 2. Drops those entire partitions
-- 3. Inserts all new data for those partitions</div>

                <h3>Advanced Partition Management</h3>
                <div class="code-block">-- Dynamic Partition Overwrite
{{
  config(
    materialized='incremental',
    incremental_strategy='insert_overwrite',
    partition_by={
      'field': 'event_date',
      'data_type': 'date',
      'granularity': 'day'
    }
  )
}}

with processed_events as (
  select
    event_id,
    user_id,
    event_type,
    event_timestamp,
    date(event_timestamp) as event_date,
    
    -- Calculate derived metrics that might change with reprocessing
    count(*) over (
      partition by user_id, date(event_timestamp)
    ) as daily_event_count,
    
    lag(event_timestamp) over (
      partition by user_id 
      order by event_timestamp
    ) as previous_event_timestamp
    
  from {{ ref('stg_events') }}
  
  {% if is_incremental() %}
    where date(event_timestamp) in (
      -- Dynamically determine which partitions to overwrite
      {% set overwrite_dates %}
        select distinct date(event_timestamp)
        from {{ ref('stg_events') }}
        where _loaded_at > (
          select max(_loaded_at) 
          from {{ this }}
        )
      {% endset %}
      
      {{ dbt_utils.get_query_results_as_dict(overwrite_dates)['date'] | join(', ') }}
    )
  {% endif %}
)

select * from processed_events

-- Hourly Partitioning Example
{{
  config(
    materialized='incremental',
    incremental_strategy='insert_overwrite',
    partition_by={
      'field': 'event_hour',
      'data_type': 'timestamp',
      'granularity': 'hour'
    }
  )
}}

select
  event_id,
  user_id,
  event_timestamp,
  timestamp_trunc(event_timestamp, HOUR) as event_hour,
  properties
from {{ ref('stg_realtime_events') }}

{% if is_incremental() %}
  where timestamp_trunc(event_timestamp, HOUR) >= 
    timestamp_sub(current_timestamp(), interval 6 hour)
{% endif %}</div>

                <h3>Perfect Use Cases</h3>
                <div class="strategy-overview">
                    <div class="strategy-card">
                        <h4>Daily Batch Loads</h4>
                        <p>Complete daily files from external systems where you always get the full day's data</p>
                        <div class="code-block">-- Daily sales files
where date(sale_timestamp) = current_date - 1</div>
                    </div>

                    <div class="strategy-card">
                        <h4>Data Reprocessing</h4>
                        <p>When you need to recalculate derived metrics or fix data quality issues</p>
                        <div class="code-block">-- Recalculate aggregations
where date >= '2024-01-01'</div>
                    </div>

                    <div class="strategy-card">
                        <h4>Late-Arriving Data</h4>
                        <p>When source systems frequently send updates for past dates</p>
                        <div class="code-block">-- Handle late data
where date >= current_date - 30</div>
                    </div>
                </div>

                <h3>Warehouse Support</h3>
                <div class="warehouse-support">
                    <div class="warehouse-item supported">
                        <h5>BigQuery</h5>
                        <p>✅ Native support<br>✅ Date/timestamp partitioning<br>✅ Automatic partition pruning</p>
                    </div>
                    <div class="warehouse-item supported">
                        <h5>Databricks</h5>
                        <p>✅ Delta Lake partitions<br>✅ Dynamic partition overwrite<br>✅ OPTIMIZE commands</p>
                    </div>
                    <div class="warehouse-item partial">
                        <h5>Spark</h5>
                        <p>✅ Partition overwrite<br>⚠️ Configuration dependent<br>✅ Hive-style partitions</p>
                    </div>
                    <div class="warehouse-item not-supported">
                        <h5>Snowflake</h5>
                        <p>❌ No native partition overwrite<br>⚠️ Falls back to delete+insert<br>✅ Clustering keys help</p>
                    </div>
                    <div class="warehouse-item not-supported">
                        <h5>Redshift</h5>
                        <p>❌ Limited partition support<br>⚠️ Falls back to delete+insert<br>✅ Sort keys help</p>
                    </div>
                </div>

                <div class="pros-cons">
                    <div class="pros">
                        <h5>✅ Advantages</h5>
                        <ul>
                            <li><strong>Complete refresh</strong>: Handles all types of changes (I/U/D)</li>
                            <li><strong>Data consistency</strong>: Entire partition is always consistent</li>
                            <li><strong>Handles late data</strong>: Perfect for late-arriving updates</li>
                            <li><strong>Reprocessing friendly</strong>: Easy to recompute historical data</li>
                            <li><strong>High performance</strong>: Leverages partition pruning</li>
                        </ul>
                    </div>
                    <div class="cons">
                        <h5>❌ Limitations</h5>
                        <ul>
                            <li><strong>Requires partitioning</strong>: Only works with partitioned tables</li>
                            <li><strong>Limited warehouse support</strong>: Not available everywhere</li>
                            <li><strong>Coarse granularity</strong>: Updates entire partitions</li>
                            <li><strong>Resource intensive</strong>: Rewrites large amounts of data</li>
                        </ul>
                    </div>
                </div>
            </div>

            <div id="microbatch" class="section">
                <h2>⚡ Microbatch Strategy</h2>
                
                <p>The <span class="highlight">microbatch</span> strategy (dbt 1.9+) processes data in time-based batches automatically, optimizing performance for large time-series datasets.</p>

                <h3>Basic Implementation</h3>
                <p><strong>📋 Code Examples:</strong> 
                <a href="https://github.com/konradKolenda/konradKolenda.github.io/blob/main/dbt/code_examples/dbt_incremental_strategies_guide/11_microbatch_basic.sql" target="_blank">Basic Microbatch</a> | 
                <a href="https://github.com/konradKolenda/konradKolenda.github.io/blob/main/dbt/code_examples/dbt_incremental_strategies_guide/12_microbatch_advanced.sql" target="_blank">Advanced Configuration</a> | 
                <a href="https://github.com/konradKolenda/konradKolenda.github.io/blob/main/dbt/code_examples/dbt_incremental_strategies_guide/13_microbatch_custom_logic.sql" target="_blank">Custom Logic</a>
                </p>
                <div class="code-block">{{
  config(
    materialized='incremental',
    incremental_strategy='microbatch',
    event_time='order_timestamp',
    batch_size='day'
  )
}}

select
  order_id,
  customer_id,
  order_amount,
  order_status,
  order_timestamp,
  
  -- Calculations are done per batch
  sum(order_amount) over (
    partition by customer_id, date(order_timestamp)
  ) as daily_customer_total
  
from {{ ref('stg_orders') }}

-- dbt automatically handles:
-- 1. Splitting data into daily batches
-- 2. Processing each batch incrementally
-- 3. Handling overlapping data between batches</div>

                <h3>Advanced Microbatch Configuration</h3>
                <div class="code-block">-- Hourly Microbatches
{{
  config(
    materialized='incremental',
    incremental_strategy='microbatch',
    event_time='event_timestamp',
    batch_size='hour',
    lookback='3 hours'  -- Reprocess last 3 hours for late data
  )
}}

with event_metrics as (
  select
    event_id,
    user_id,
    event_type,
    event_timestamp,
    
    -- Calculate session boundaries (cross-batch calculations)
    lag(event_timestamp, 1, '1900-01-01'::timestamp) over (
      partition by user_id 
      order by event_timestamp
    ) as prev_event_timestamp,
    
    case when 
      event_timestamp - lag(event_timestamp) over (
        partition by user_id 
        order by event_timestamp
      ) > interval '30 minutes'
    then 1 else 0 end as new_session_flag
    
  from {{ ref('stg_events') }}
)

select
  *,
  sum(new_session_flag) over (
    partition by user_id 
    order by event_timestamp 
    rows unbounded preceding
  ) as session_id
from event_metrics

-- Custom Batch Processing Logic
{{
  config(
    materialized='incremental',
    incremental_strategy='microbatch',
    event_time='created_at',
    batch_size='day',
    
    -- Custom batch logic
    begin_batch_macro='get_batch_start',
    end_batch_macro='get_batch_end'
  )
}}

-- Custom macros in macros/batch_logic.sql
{% macro get_batch_start() %}
  select min(created_at) from {{ ref('stg_source') }}
  where date(created_at) = '{{ var("batch_date") }}'
{% endmacro %}

{% macro get_batch_end() %}
  select max(created_at) from {{ ref('stg_source') }}
  where date(created_at) = '{{ var("batch_date") }}'
{% endmacro %}</div>

                <h3>Microbatch Benefits</h3>
                <div class="strategy-overview">
                    <div class="strategy-card">
                        <h4>Automatic Parallelization</h4>
                        <p>dbt automatically runs batches in parallel when possible, dramatically improving performance</p>
                    </div>

                    <div class="strategy-card">
                        <h4>Memory Optimization</h4>
                        <p>Processes smaller chunks of data, reducing memory pressure and avoiding OOM errors</p>
                    </div>

                    <div class="strategy-card">
                        <h4>Late Data Handling</h4>
                        <p>Built-in lookback windows automatically reprocess recent batches when late data arrives</p>
                    </div>

                    <div class="strategy-card">
                        <h4>Failure Recovery</h4>
                        <p>If a batch fails, only that batch needs to be rerun, not the entire model</p>
                    </div>
                </div>

                <div class="pros-cons">
                    <div class="pros">
                        <h5>✅ Advantages</h5>
                        <ul>
                            <li><strong>Optimized performance</strong>: Automatic parallelization and memory management</li>
                            <li><strong>Built-in late data handling</strong>: Configurable lookback windows</li>
                            <li><strong>Failure recovery</strong>: Granular retry capabilities</li>
                            <li><strong>Memory efficient</strong>: Processes data in smaller chunks</li>
                            <li><strong>Universal support</strong>: Works on all warehouses</li>
                        </ul>
                    </div>
                    <div class="cons">
                        <h5>❌ Limitations</h5>
                        <ul>
                            <li><strong>dbt 1.9+ only</strong>: Requires latest dbt version</li>
                            <li><strong>Time-based data only</strong>: Requires event_time column</li>
                            <li><strong>Complex debugging</strong>: Multiple batches make troubleshooting harder</li>
                            <li><strong>No cross-batch joins</strong>: Limited for complex transformations</li>
                        </ul>
                    </div>
                </div>
            </div>

            <div id="decision-guide" class="section">
                <h2>🧭 Decision Guide: Which Strategy to Choose</h2>
                
                <div class="decision-tree">
                    <h4>🎯 Strategy Selection Decision Tree</h4>
                    
                    <div class="decision-step">
                        <strong>Step 1: Data Type Analysis</strong>
                        <ul>
                            <li><strong>Immutable events/logs?</strong> → Use <code>append</code></li>
                            <li><strong>Time-partitioned data with complete loads?</strong> → Use <code>insert_overwrite</code></li>
                            <li><strong>Large time-series with updates?</strong> → Use <code>microbatch</code></li>
                            <li><strong>Traditional dimensional/fact tables?</strong> → Continue to Step 2</li>
                        </ul>
                    </div>

                    <div class="decision-step">
                        <strong>Step 2: Update Pattern Analysis</strong>
                        <ul>
                            <li><strong>No updates needed (insert-only)?</strong> → Use <code>append</code></li>
                            <li><strong>Frequent updates to existing records?</strong> → Continue to Step 3</li>
                            <li><strong>Occasional updates?</strong> → Use <code>delete+insert</code> (safe default)</li>
                        </ul>
                    </div>

                    <div class="decision-step">
                        <strong>Step 3: Performance & Scale Analysis</strong>
                        <ul>
                            <li><strong>Small-medium tables (&lt;10M rows)?</strong> → Use <code>delete+insert</code></li>
                            <li><strong>Large tables (>10M rows) with many updates?</strong> → Use <code>merge</code></li>
                            <li><strong>Warehouse doesn't support MERGE?</strong> → Use <code>delete+insert</code></li>
                        </ul>
                    </div>

                    <div class="decision-step">
                        <strong>Step 4: Deletion Requirements</strong>
                        <ul>
                            <li><strong>Need to handle source deletions?</strong> → Use <code>merge</code> with delete logic</li>
                            <li><strong>Soft deletes acceptable?</strong> → Use any strategy + soft delete pattern</li>
                            <li><strong>Partition-level deletion?</strong> → Use <code>insert_overwrite</code></li>
                        </ul>
                    </div>
                </div>

                <h3>Quick Reference by Use Case</h3>
                <table class="comparison-table">
                    <thead>
                        <tr>
                            <th>Use Case</th>
                            <th>Recommended Strategy</th>
                            <th>Alternative</th>
                            <th>Key Configuration</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Event logging / Clickstream</td>
                            <td><code>append</code></td>
                            <td><code>microbatch</code></td>
                            <td>Partition by date, no unique_key</td>
                        </tr>
                        <tr>
                            <td>Customer dimension</td>
                            <td><code>merge</code></td>
                            <td><code>delete+insert</code></td>
                            <td>unique_key='customer_id'</td>
                        </tr>
                        <tr>
                            <td>Daily sales aggregates</td>
                            <td><code>insert_overwrite</code></td>
                            <td><code>merge</code></td>
                            <td>Partition by sale_date</td>
                        </tr>
                        <tr>
                            <td>IoT sensor data</td>
                            <td><code>microbatch</code></td>
                            <td><code>append</code></td>
                            <td>event_time='timestamp', batch_size='hour'</td>
                        </tr>
                        <tr>
                            <td>Financial transactions</td>
                            <td><code>append</code></td>
                            <td><code>microbatch</code></td>
                            <td>Immutable with unique transaction_id</td>
                        </tr>
                        <tr>
                            <td>User profile updates</td>
                            <td><code>merge</code></td>
                            <td><code>delete+insert</code></td>
                            <td>unique_key='user_id', exclude created_at</td>
                        </tr>
                        <tr>
                            <td>Inventory snapshots</td>
                            <td><code>insert_overwrite</code></td>
                            <td><code>delete+insert</code></td>
                            <td>Partition by snapshot_date</td>
                        </tr>
                        <tr>
                            <td>Application logs</td>
                            <td><code>append</code></td>
                            <td><code>microbatch</code></td>
                            <td>Partition by log_date</td>
                        </tr>
                    </tbody>
                </table>

                <h3>Performance Optimization Tips</h3>
                <p><strong>📋 Code Example:</strong> 
                <a href="https://github.com/konradKolenda/konradKolenda.github.io/blob/main/dbt/code_examples/dbt_incremental_strategies_guide/14_performance_optimization.sql" target="_blank">Performance Optimization</a>
                </p>
                <div class="code-block">-- Universal Performance Tips for All Strategies

-- 1. Always use appropriate filtering
{% if is_incremental() %}
  where updated_at > (select max(updated_at) from {{ this }})
  -- Add buffer for late-arriving data
  and updated_at > current_timestamp - interval '1 hour'
{% endif %}

-- 2. Use partitioning when possible
{{
  config(
    partition_by={'field': 'created_date', 'data_type': 'date'},
    cluster_by=['status', 'customer_id']  -- Frequently filtered columns
  )
}}

-- 3. Add data quality checks
select * from source_data
where id is not null  -- Prevent NULL unique_key issues
  and created_at is not null  -- Prevent partition issues
  and {{ not_null_proportion('email', 0.95) }}  -- Data quality macro

-- 4. Monitor query performance
{{ config(post_hook=[
  "insert into metadata.model_performance 
   select '{{ this }}', current_timestamp, 
   '{{ invocation_id }}', {{ query_tag() }}"
]) }}

-- 5. Use appropriate batch sizing
{% if var('full_refresh', false) %}
  -- Full refresh: no filtering
  select * from source_data
{% else %}
  -- Incremental: process last N days to handle late data
  where created_date >= current_date - {{ var('lookback_days', 3) }}
{% endif %}</div>

                <div class="warning-box">
                    <h4>🚨 Common Mistakes to Avoid</h4>
                    <ul>
                        <li><strong>Using append for dimensional data</strong> - leads to duplicates</li>
                        <li><strong>Forgetting unique_key</strong> - prevents updates from working</li>
                        <li><strong>NULL values in unique_key</strong> - causes unpredictable behavior</li>
                        <li><strong>Wrong partition granularity</strong> - too fine causes many small files</li>
                        <li><strong>No late data handling</strong> - causes data loss</li>
                        <li><strong>Ignoring warehouse capabilities</strong> - using unsupported strategies</li>
                        <li><strong>Not testing with real data patterns</strong> - surprises in production</li>
                    </ul>
                </div>

                <div class="recommendation-box">
                    <h4>🎯 Final Recommendations</h4>
                    <p><strong>For beginners:</strong> Start with <code>delete+insert</code> - it's reliable and works everywhere</p>
                    <p><strong>For performance:</strong> Graduate to <code>merge</code> when you have large tables with frequent updates</p>
                    <p><strong>For event data:</strong> Use <code>append</code> but be very careful about uniqueness</p>
                    <p><strong>For batch loads:</strong> <code>insert_overwrite</code> is perfect for complete daily/hourly datasets</p>
                    <p><strong>For modern stacks:</strong> <code>microbatch</code> provides the best balance of performance and reliability</p>
                </div>
            </div>

            <div class="section">
                <h2>🎓 Summary & Next Steps</h2>
                <p>Understanding incremental strategies is crucial for building efficient, scalable dbt models. Each strategy has its place:</p>
                
                <ul>
                    <li><strong>delete+insert</strong>: Your reliable default choice</li>
                    <li><strong>merge</strong>: The performance champion for updates</li>
                    <li><strong>append</strong>: The speed demon for immutable data</li>
                    <li><strong>insert_overwrite</strong>: The complete refresh for partitioned data</li>
                    <li><strong>microbatch</strong>: The modern solution for large time-series</li>
                </ul>

                <p><strong>Practice Path:</strong></p>
                <ol>
                    <li>Start with <code>delete+insert</code> to learn the concepts</li>
                    <li>Experiment with <code>append</code> for event data</li>
                    <li>Try <code>merge</code> when you need better performance</li>
                    <li>Explore <code>insert_overwrite</code> for time-partitioned data</li>
                    <li>Test <code>microbatch</code> for large-scale processing</li>
                </ol>

                <p>Remember: <span class="highlight">Choose based on your data patterns, not just performance</span>. The wrong strategy can cause data corruption, while the right strategy makes your pipelines both fast and reliable.</p>
            </div>

            <div class="section">
                <h2>📚 Official dbt Documentation</h2>
                <div class="recommendation-box">
                    <p>For the most up-to-date information and comprehensive details, refer to the official dbt documentation:</p>
                    <ul>
                        <li><strong><a href="https://docs.getdbt.com/docs/build/incremental-models" target="_blank">Incremental models</a></strong> - Official guide to dbt incremental materialization</li>
                        <li><strong><a href="https://docs.getdbt.com/best-practices/materializations/1-guide-overview" target="_blank">Materializations best practices</a></strong> - Guide to choosing and implementing dbt materializations</li>
                    </ul>
                    <p><em>These resources provide the authoritative source for dbt incremental strategies and are regularly updated by the dbt Labs team.</em></p>
                </div>
            </div>
        </div>
    </div>
</body>
</html>