name: Dynamic Branch Environment Creation

on:
  pull_request:
    types: [opened, synchronize, reopened]
  pull_request_target:
    types: [closed]

jobs:
  create-environment:
    if: github.event.action != 'closed'
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        pip install dbt-snowflake dbt-core
        dbt deps
        
    - name: Generate environment name
      id: env
      run: |
        # Create safe environment name from branch
        BRANCH_NAME=$(echo "${{ github.head_ref }}" | sed 's/[^a-zA-Z0-9]/_/g' | tr '[:upper:]' '[:lower:]')
        SCHEMA_NAME="pr_${BRANCH_NAME}_${{ github.event.number }}"
        
        # Truncate if too long (Snowflake limit is 255 chars)
        SCHEMA_NAME=$(echo "$SCHEMA_NAME" | cut -c1-50)
        
        echo "branch_name=$BRANCH_NAME" >> $GITHUB_OUTPUT
        echo "schema_name=$SCHEMA_NAME" >> $GITHUB_OUTPUT
        echo "pr_number=${{ github.event.number }}" >> $GITHUB_OUTPUT
        
    - name: Create PR environment
      run: |
        echo "Creating environment: ${{ steps.env.outputs.schema_name }}"
        
        # Run dbt with dynamic schema
        dbt run --target dev --vars '{"schema_override": "${{ steps.env.outputs.schema_name }}"}'
        dbt test --target dev --vars '{"schema_override": "${{ steps.env.outputs.schema_name }}"}'
        
        # Generate and upload documentation
        dbt docs generate --target dev --vars '{"schema_override": "${{ steps.env.outputs.schema_name }}"}'
        
      env:
        DBT_SNOWFLAKE_ACCOUNT: ${{ secrets.DBT_SNOWFLAKE_ACCOUNT }}
        DBT_SNOWFLAKE_USER: ${{ secrets.DBT_SNOWFLAKE_USER }}
        DBT_SNOWFLAKE_PASSWORD: ${{ secrets.DBT_SNOWFLAKE_PASSWORD }}
        DBT_SNOWFLAKE_ROLE: ${{ secrets.DBT_SNOWFLAKE_ROLE }}
        DBT_SNOWFLAKE_DATABASE: ${{ secrets.DBT_SNOWFLAKE_DATABASE }}
        DBT_SNOWFLAKE_WAREHOUSE: ${{ secrets.DBT_SNOWFLAKE_WAREHOUSE }}
        DBT_SNOWFLAKE_SCHEMA: ${{ steps.env.outputs.schema_name }}
        
    - name: Upload docs to S3 (optional)
      run: |
        # Upload generated docs to S3 for easy access
        aws s3 sync target/ s3://dbt-docs-bucket/pr-${{ steps.env.outputs.pr_number }}/
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        
    - name: Comment on PR with environment details
      uses: actions/github-script@v6
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const { schema_name, pr_number } = ${{ toJson(steps.env.outputs) }};
          
          const comment = `## 🚀 Preview Environment Created
          
          **Environment Details:**
          - **Schema:** \`${schema_name}\`
          - **Database:** \`${{ secrets.DBT_SNOWFLAKE_DATABASE }}\`
          - **Warehouse:** \`${{ secrets.DBT_SNOWFLAKE_WAREHOUSE }}\`
          
          **Access Links:**
          - 📊 [View Documentation](https://dbt-docs-bucket.s3.amazonaws.com/pr-${pr_number}/index.html)
          - 🔍 [Query Schema in Snowflake](https://app.snowflake.com/your-account/worksheet)
          
          **Available Tables/Views:**
          Run \`SHOW TABLES IN SCHEMA ${schema_name};\` in Snowflake to see all created objects.
          
          ---
          
          Environment will be automatically cleaned up when this PR is closed.`;
          
          // Check if comment already exists
          const { data: comments } = await github.rest.issues.listComments({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
          });
          
          const existingComment = comments.find(comment => 
            comment.body.includes('Preview Environment Created')
          );
          
          if (existingComment) {
            // Update existing comment
            await github.rest.issues.updateComment({
              comment_id: existingComment.id,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          } else {
            // Create new comment
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          }

  cleanup-environment:
    if: github.event.action == 'closed'
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        pip install dbt-snowflake dbt-core
        
    - name: Generate environment name
      id: env
      run: |
        BRANCH_NAME=$(echo "${{ github.head_ref }}" | sed 's/[^a-zA-Z0-9]/_/g' | tr '[:upper:]' '[:lower:]')
        SCHEMA_NAME="pr_${BRANCH_NAME}_${{ github.event.number }}"
        SCHEMA_NAME=$(echo "$SCHEMA_NAME" | cut -c1-50)
        echo "schema_name=$SCHEMA_NAME" >> $GITHUB_OUTPUT
        
    - name: Cleanup PR environment
      run: |
        echo "Cleaning up environment: ${{ steps.env.outputs.schema_name }}"
        
        # Drop the schema and all its objects
        dbt run-operation drop_schema --args '{schema_name: ${{ steps.env.outputs.schema_name }}}' --target dev
        
      env:
        DBT_SNOWFLAKE_ACCOUNT: ${{ secrets.DBT_SNOWFLAKE_ACCOUNT }}
        DBT_SNOWFLAKE_USER: ${{ secrets.DBT_SNOWFLAKE_USER }}
        DBT_SNOWFLAKE_PASSWORD: ${{ secrets.DBT_SNOWFLAKE_PASSWORD }}
        DBT_SNOWFLAKE_ROLE: ${{ secrets.DBT_SNOWFLAKE_ROLE }}
        DBT_SNOWFLAKE_DATABASE: ${{ secrets.DBT_SNOWFLAKE_DATABASE }}
        DBT_SNOWFLAKE_WAREHOUSE: ${{ secrets.DBT_SNOWFLAKE_WAREHOUSE }}
        
    - name: Cleanup S3 docs (optional)
      run: |
        # Remove docs from S3
        aws s3 rm s3://dbt-docs-bucket/pr-${{ github.event.number }}/ --recursive
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}