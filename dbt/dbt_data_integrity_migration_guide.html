<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Integrity in dbt: A Migration Guide from Traditional SQL</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 1000px;
            margin: 0 auto;
            padding: 40px 20px;
            line-height: 1.6;
            color: #333;
        }
        
        h1 {
            color: #ff6939;
            text-align: center;
            border-bottom: 3px solid #ff6939;
            padding-bottom: 10px;
            margin-bottom: 30px;
        }
        
        h2 {
            color: #2c3e50;
            border-left: 4px solid #ff6939;
            padding-left: 15px;
            margin-top: 40px;
        }
        
        h3 {
            color: #34495e;
            margin-top: 30px;
        }
        
        .code-block {
            background: #2c3e50;
            color: #ecf0f1;
            font-family: 'Monaco', 'Consolas', monospace;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            margin: 15px 0;
            border-left: 4px solid #ff6939;
        }
        
        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .comparison-table th,
        .comparison-table td {
            padding: 12px 15px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        
        .comparison-table th {
            background: #34495e;
            color: white;
            font-weight: 600;
        }
        
        .comparison-table tr:hover {
            background: #f5f5f5;
        }
        
        .highlight-box {
            background: #e8f4f8;
            border: 1px solid #bee5eb;
            border-radius: 5px;
            padding: 20px;
            margin: 20px 0;
        }
        
        .warning-box {
            background: #fff3cd;
            border: 1px solid #ffeaa7;
            border-radius: 5px;
            padding: 20px;
            margin: 20px 0;
        }
        
        .pros-cons {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 20px 0;
        }
        
        .pros {
            background: #d4edda;
            border: 1px solid #c3e6cb;
            border-radius: 5px;
            padding: 15px;
        }
        
        .cons {
            background: #f8d7da;
            border: 1px solid #f5c6cb;
            border-radius: 5px;
            padding: 15px;
        }
        
        .footer-links {
            background: #f8f9fa;
            border-radius: 8px;
            padding: 20px;
            margin-top: 40px;
            text-align: center;
        }
        
        .footer-links h3 {
            margin-top: 0;
            color: #2c3e50;
        }
        
        .footer-links a {
            color: #ff6939;
            text-decoration: none;
            margin: 0 10px;
        }
        
        .footer-links a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <h1>Data Integrity in dbt: A Migration Guide from Traditional SQL</h1>
    
    <div class="highlight-box">
        <strong>Target Audience:</strong> Data professionals transitioning from traditional RDBMS systems (SQL Server, Oracle, PostgreSQL) to modern data stack with dbt, particularly those familiar with database constraints and seeking equivalent data integrity patterns.
    </div>
    
    <h2>Introduction: The Paradigm Shift</h2>
    
    <p>Moving from traditional database systems like Microsoft SQL Server to a modern data stack with dbt represents a fundamental shift in how we approach data integrity. Instead of relying on database-enforced constraints at the table level, dbt introduces a <strong>transformation-time validation</strong> approach that provides greater flexibility and transparency.</p>
    
    <h2>Traditional SQL Constraints vs. dbt Approach</h2>
    
    <table class="comparison-table">
        <thead>
            <tr>
                <th>Traditional SQL Constraint</th>
                <th>Purpose</th>
                <th>dbt Equivalent</th>
                <th>Implementation Method</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>PRIMARY KEY</td>
                <td>Unique identifier, not null</td>
                <td>Data Tests + Model Contracts</td>
                <td><code>unique</code> + <code>not_null</code> tests</td>
            </tr>
            <tr>
                <td>FOREIGN KEY</td>
                <td>Referential integrity</td>
                <td>Relationship Tests</td>
                <td><code>relationships</code> test</td>
            </tr>
            <tr>
                <td>UNIQUE</td>
                <td>No duplicate values</td>
                <td>Unique Data Test</td>
                <td><code>unique</code> test</td>
            </tr>
            <tr>
                <td>NOT NULL</td>
                <td>Required values</td>
                <td>Not Null Data Test</td>
                <td><code>not_null</code> test</td>
            </tr>
            <tr>
                <td>CHECK</td>
                <td>Value validation</td>
                <td>Accepted Values Test</td>
                <td><code>accepted_values</code> test</td>
            </tr>
        </tbody>
    </table>
    
    <h2>Core Concepts in dbt Data Integrity</h2>
    
    <h3>1. Data Tests: The Foundation</h3>
    
    <p>In traditional SQL, constraints are enforced at insert/update time. In dbt, <strong>data tests</strong> are SQL queries that validate your data assumptions and can be run as part of your transformation workflow.</p>
    
    <div class="code-block">
-- Traditional SQL Server Approach
CREATE TABLE customers (
    customer_id INT PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    status VARCHAR(20) CHECK (status IN ('active', 'inactive', 'suspended')),
    created_at DATETIME NOT NULL
);

-- dbt Approach: schema.yml
version: 2
models:
  - name: customers
    description: "Customer master table"
    columns:
      - name: customer_id
        description: "Unique customer identifier"
        data_tests:
          - unique
          - not_null
      - name: email
        description: "Customer email address"
        data_tests:
          - unique
          - not_null
      - name: status
        description: "Customer account status"
        data_tests:
          - accepted_values:
              values: ['active', 'inactive', 'suspended']
      - name: created_at
        description: "Account creation timestamp"
        data_tests:
          - not_null
    </div>
    
    <h3>2. Model Contracts: Schema Enforcement</h3>
    
    <p>Model contracts in dbt provide upfront guarantees about your model's structure, similar to how table schemas work in traditional databases.</p>
    
    <div class="code-block">
-- Traditional SQL Server: Schema is enforced at table level
-- dbt: Schema is enforced through model contracts

-- models/customers.sql
{{
  config(
    contract="enforce"
  )
}}

version: 2
models:
  - name: customers
    config:
      contract:
        enforced: true
    columns:
      - name: customer_id
        data_type: int
        constraints:
          - type: not_null
          - type: primary_key
      - name: email
        data_type: varchar(255)
        constraints:
          - type: not_null
          - type: unique
    </div>
    
    <h3>3. Referential Integrity with Relationships Tests</h3>
    
    <p>Foreign key relationships in dbt are validated through relationships tests, providing the same integrity guarantees as traditional FOREIGN KEY constraints.</p>
    
    <div class="code-block">
-- Traditional SQL Server
ALTER TABLE orders 
ADD CONSTRAINT FK_orders_customers 
FOREIGN KEY (customer_id) REFERENCES customers(customer_id);

-- dbt Equivalent
version: 2
models:
  - name: orders
    columns:
      - name: customer_id
        description: "Reference to customers table"
        data_tests:
          - relationships:
              to: ref('customers')
              field: customer_id
    </div>
    
    <h2>Migration Strategies</h2>
    
    <h3>Phase 1: Assessment and Planning</h3>
    
    <div class="highlight-box">
        <strong>Key Steps:</strong>
        <ul>
            <li>Inventory existing constraints in your traditional database</li>
            <li>Identify critical business rules enforced by constraints</li>
            <li>Map constraint types to dbt test equivalents</li>
            <li>Plan testing strategy and validation workflows</li>
        </ul>
    </div>
    
    <h3>Phase 2: Implementing dbt Data Tests</h3>
    
    <div class="code-block">
-- Example migration from SQL Server to dbt
-- SQL Server Table Definition
/*
CREATE TABLE products (
    product_id INT IDENTITY(1,1) PRIMARY KEY,
    sku VARCHAR(50) UNIQUE NOT NULL,
    category_id INT FOREIGN KEY REFERENCES categories(category_id),
    price DECIMAL(10,2) CHECK (price > 0),
    status VARCHAR(20) DEFAULT 'active' CHECK (status IN ('active', 'discontinued'))
);
*/

-- dbt schema.yml equivalent
version: 2
models:
  - name: products
    description: "Product master data"
    columns:
      - name: product_id
        description: "Auto-generated product identifier"
        data_tests:
          - unique
          - not_null
      - name: sku
        description: "Stock keeping unit"
        data_tests:
          - unique
          - not_null
      - name: category_id
        description: "Product category reference"
        data_tests:
          - not_null
          - relationships:
              to: ref('categories')
              field: category_id
      - name: price
        description: "Product price"
        data_tests:
          - not_null
          - dbt_utils.expression_is_true:
              expression: "> 0"
      - name: status
        description: "Product status"
        data_tests:
          - accepted_values:
              values: ['active', 'discontinued']
    </div>
    
    <h3>Phase 3: Advanced Patterns</h3>
    
    <h4>Custom Tests for Complex Business Rules</h4>
    
    <div class="code-block">
-- tests/assert_price_consistency.sql
-- Custom test equivalent to complex CHECK constraint
SELECT 
    product_id,
    sku,
    price,
    discount_price
FROM {{ ref('products') }}
WHERE discount_price >= price
    OR discount_price < 0
    </div>
    
    <h4>Multi-Column Constraints</h4>
    
    <div class="code-block">
-- Traditional SQL: Composite key
-- ALTER TABLE order_items ADD CONSTRAINT PK_order_items 
-- PRIMARY KEY (order_id, product_id);

-- dbt equivalent
version: 2
models:
  - name: order_items
    data_tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - order_id
            - product_id
    </div>
    
    <h2>Pros and Cons Comparison</h2>
    
    <div class="pros-cons">
        <div class="pros">
            <h4>✅ dbt Advantages</h4>
            <ul>
                <li><strong>Flexibility:</strong> Tests can be modified without table locks</li>
                <li><strong>Transparency:</strong> All validation logic is version-controlled</li>
                <li><strong>CI/CD Integration:</strong> Tests run as part of deployment pipeline</li>
                <li><strong>Custom Logic:</strong> Complex business rules easily implemented</li>
                <li><strong>Data Quality Insights:</strong> Failed tests provide actionable data quality reports</li>
                <li><strong>Documentation:</strong> Tests serve as living documentation</li>
            </ul>
        </div>
        <div class="cons">
            <h4>❌ Trade-offs</h4>
            <ul>
                <li><strong>Runtime Enforcement:</strong> No immediate rejection of invalid data</li>
                <li><strong>Resource Usage:</strong> Tests consume compute resources</li>
                <li><strong>Platform Differences:</strong> Constraint enforcement varies by data warehouse</li>
                <li><strong>Learning Curve:</strong> New testing paradigm to master</li>
                <li><strong>Timing:</strong> Issues discovered after data loading</li>
            </ul>
        </div>
    </div>
    
    <h2>Best Practices for Migration</h2>
    
    <h3>1. Start with Critical Constraints</h3>
    <div class="warning-box">
        <strong>Priority Order:</strong>
        <ol>
            <li>Primary key uniqueness and not-null checks</li>
            <li>Foreign key relationships</li>
            <li>Business-critical value validations</li>
            <li>Data type and format validations</li>
        </ol>
    </div>
    
    <h3>2. Implement Progressive Validation</h3>
    
    <div class="code-block">
# dbt_project.yml - Configure test severity
data_tests:
  warn_if: ">= 1"     # Warning for any failures
  error_if: ">= 10"   # Error if 10+ failures
  
# Gradual rollout approach
models:
  my_project:
    staging:
      +data_tests:
        +severity: warn
    marts:
      +data_tests:
        +severity: error
    </div>
    
    <h3>3. Leverage dbt Packages</h3>
    
    <div class="code-block">
# packages.yml
packages:
  - package: dbt-labs/dbt_utils
    version: 1.1.1
  - package: calogica/dbt_expectations
    version: 0.10.1

# Enhanced testing capabilities
models:
  - name: customers
    columns:
      - name: email
        data_tests:
          - dbt_expectations.expect_column_values_to_match_regex:
              regex: "^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$"
    </div>
    
    <h2>Advanced Migration Patterns</h2>
    
    <h3>Hybrid Approach: Database + dbt Constraints</h3>
    
    <p>For organizations requiring both immediate enforcement and comprehensive testing:</p>
    
    <div class="code-block">
-- Stage 1: Load with minimal database constraints
CREATE TABLE raw_customers (
    customer_id INT NOT NULL,  -- Keep essential constraints
    email VARCHAR(255),
    -- Other columns without constraints
);

-- Stage 2: dbt transformation with comprehensive testing
-- models/staging/stg_customers.sql
{{ config(materialized='table') }}

SELECT 
    customer_id,
    LOWER(TRIM(email)) as email,
    -- Data cleaning and validation
FROM {{ source('raw', 'raw_customers') }}

-- Stage 3: Comprehensive dbt tests ensure data quality
    </div>
    
    <h3>Data Quality Monitoring</h3>
    
    <div class="code-block">
-- tests/data_quality/customer_email_format.sql
{{ config(severity='warn', store_failures=true) }}

SELECT 
    customer_id,
    email,
    'Invalid email format' as failure_reason
FROM {{ ref('customers') }}
WHERE email NOT REGEXP '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$'
    </div>
    
    <h2>Implementation Checklist</h2>
    
    <div class="highlight-box">
        <strong>Migration Checklist:</strong>
        <ol>
            <li>✅ <strong>Audit existing constraints</strong> - Document all current database constraints</li>
            <li>✅ <strong>Map to dbt tests</strong> - Identify equivalent dbt testing patterns</li>
            <li>✅ <strong>Implement core tests</strong> - Start with unique, not_null, relationships</li>
            <li>✅ <strong>Add custom validations</strong> - Implement business rule tests</li>
            <li>✅ <strong>Configure CI/CD</strong> - Integrate tests into deployment pipeline</li>
            <li>✅ <strong>Monitor and iterate</strong> - Establish data quality monitoring</li>
            <li>✅ <strong>Documentation</strong> - Document testing strategy and patterns</li>
            <li>✅ <strong>Training</strong> - Educate team on new testing paradigms</li>
        </ol>
    </div>
    
    <h2>Conclusion</h2>
    
    <p>Migrating from traditional SQL constraints to dbt's data testing approach represents a shift from <strong>prevention-based</strong> to <strong>detection-based</strong> data integrity. While this requires adjusting your mental model, it offers significant advantages in flexibility, maintainability, and integration with modern data workflows.</p>
    
    <p>The key to successful migration is understanding that dbt tests provide <strong>equivalent or superior</strong> data quality guarantees while offering greater visibility and control over your data validation processes.</p>
    
    <div class="footer-links">
        <h3>Official Documentation References</h3>
        <p>
            <a href="https://docs.getdbt.com/docs/build/data-tests" target="_blank">dbt Data Tests</a> |
            <a href="https://docs.getdbt.com/reference/resource-properties/constraints" target="_blank">dbt Constraints</a> |
            <a href="https://docs.getdbt.com/docs/collaborate/govern/model-contracts" target="_blank">Model Contracts</a> |
            <a href="https://docs.getdbt.com/docs/build/data-tests#generic-data-tests" target="_blank">Generic Tests</a>
        </p>
    </div>
</body>
</html>